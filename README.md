# ðŸš« Vulgar Phrase Detector using DistilBERT

An open-source Natural Language Processing (NLP) project that identifies and classifies vulgar or offensive phrases using [DistilBERT](https://huggingface.co/distilbert-base-uncased).  
This project is designed to support moderation systems, intelligent bots, and content filters by detecting inappropriate language in real time.

<p align="center">
  <img src="https://img.shields.io/github/license/virendra-tarate/vulgar-phrase-detector" />
  <img src="https://img.shields.io/github/stars/virendra-tarate/vulgar-phrase-detector" />
  <img src="https://img.shields.io/github/forks/virendra-tarate/vulgar-phrase-detector" />
</p>

---

## ðŸ” Features

- âœ… Built using `DistilBERT`, a lighter, faster variant of BERT
- ðŸ“Š Binary classification: **Vulgar (1)** or **Non-Vulgar (0)**
- ðŸ“ Includes notebook, dataset, and pre-trained model (downloadable via release)
- âš™ï¸ Easily extendable with your own dataset or architecture
- ðŸ¤ Open to contributions and community support

---

## ðŸ“ Project Structure

vulgar-phrase-detector/  
â”œâ”€â”€ data/  
â”‚ â””â”€â”€ dataset.csv   
â”œâ”€â”€ vulgar_detector.ipynb  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ README.md  
â””â”€â”€ LICENSE  


---

## ðŸ“Š Dataset

The model is trained on a custom dataset of **8,334 text entries** labeled as:

- `0`: Non-vulgar
- `1`: Vulgar

The dataset is included under `data/dataset.csv`.  
We welcome contributions to expand and diversify the dataset! ðŸ™Œ

---

## ðŸ“¥ Download the Trained Model

Due to GitHub's 100MB file limit, the trained model is stored under **Releases**.

ðŸ‘‰ [Download model.zip from the latest release](https://github.com/virendra-tarate/vulgar-phrase-detector/releases/latest)

### After Downloading:
1. Extract `model.zip`
2. Place the extracted `model/` folder in the root of your project.

---

## ðŸš€ How to Run

### 1. Clone the Repo

```bash
git clone https://github.com/virendra-tarate/vulgar-phrase-detector.git
cd vulgar-phrase-detector
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run Prediction

```Python
from transformers import pipeline

classifier = pipeline("text-classification", model="./abuse_detection_model", tokenizer="./abuse_detection_model")

print(classifier("You are big dick head"))
print(classifier("You are so helpful, thank you!"))

```

#### Expected Output:

```bash
[{'label': 'LABEL_1', 'score': 0.98}]  # Vulgar
[{'label': 'LABEL_0', 'score': 0.99}]  # Clean

```
---

## ðŸ“ˆ Future Improvements

- [ ] REST API deployment (e.g., FastAPI)
- [ ] Data augmentation & multilingual support
- [ ] Browser extension for live moderation
- [ ] Multi-label detection: hate speech, spam, etc.

---

## ðŸ¤ Contributing

We welcome all contributions, from adding new data to improving the model.

### How to Contribute

1. **Fork** the repository
2. **Create a branch**: `git checkout -b feature/your-feature`
3. **Commit your changes**: `git commit -m "Add feature"`
4. **Push to your branch**: `git push origin feature/your-feature`
5. **Open a Pull Request**

---

## ðŸ›¡ License

This project is licensed under the [MIT License](./LICENSE).

---

## ðŸ™‹ Contact

- ðŸ‘¤ Maintainer: [Virendra Tarate](https://github.com/virendra-tarate)
- ðŸ“§ Email: virendratarte22@gmail.com

---

## ðŸ™Œ Acknowledgements

- [HuggingFace Transformers](https://huggingface.co/transformers/)
- [Google Colab](https://colab.research.google.com/)
- The open-source community â¤ï¸


> _Letâ€™s build a cleaner, more respectful internet together._
